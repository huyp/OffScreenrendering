# Off Screen Renderding 

## 渲染流程

根据苹果WWDC14 419 Core Animation技术宣讲中的图片简化而来的流程图。

16.67代表一帧的刷新时间。

![渲染流程](https://github.com/huyp/OffScreenrendering/blob/master/渲染流程.png)
## 定义

如果要在显示屏上显示内容，我们至少需要一块与屏幕像素数据量一样大的frame buffer，作为像素数据存储区域，而这也是GPU存储渲染结果的地方。如果有时因为面临一些限制，无法把渲染结果直接写入frame buffer，而是先暂存在另外的内存区域，之后再写入frame buffer，那么这个过程被称之为离屏渲染。

### ![离屏渲染](/Users/icbc_app_2/Desktop/技术分享-offScreenRendering/离屏渲染.png)

### CGContext

CGContext来画图容易被误解为离屏渲染，它实际上是CPU渲染或软件渲染。真正的离屏渲染发生在GPU.

![CGContext](/Users/icbc_app_2/Desktop/技术分享-offScreenRendering/CGContext.png)

### 画家算法

就像给一面墙涂鸦，先在刷好背景色，然后再上面绘画。每一层Layer都会按照画家算法，按次序输出的frame buffer，最后得到我们想要的结果。作为“画家”的GPU虽然可以一层一层往画布上进行输出，但是无法在某一层渲染完成之后，再回过头来擦除/改变其中的某个部分——因为在这一层之前的若干层layer像素数据，已经在渲染中被永久覆盖了。也就是framebuffer只有一层，之前被覆盖的部分已经被丢弃。

![画家算法](/Users/icbc_app_2/Desktop/技术分享-offScreenRendering/画家算法.png)

### 离屏渲染的本质

GPU的操作是高度流水线化的。本来所有计算工作都在有条不紊地正在向frame buffer输出。当Draw Calls发现即将绘制的buffer背离画家算法（我认为对于UIKit而言，离屏渲染是可以预知的，Draw Calls阶段就能发现输出背离画家算法，直接开辟offscreen buffer，比起frame buffer发现输入错误而导致返工更高效，这种猜测在Border的实验中可以得到验证），那么会自动的开辟offscreen buffer来处理复杂的渲染，之后再交给frame buffer。

### 触发离屏渲染

触发离屏渲染就是背离画家算法，那么什么样的Layer会导致画家算法失效？

常见的会触发离屏渲染因素如下：

1. mask 
2. masksToBounds 
3. shouldRasterize 
4. shadow 
5. alpha  
6. opacity 
7. blur 

### 开发调试

模拟器和真机都提供了“Color Offscreen render”的选项，如果发生离屏渲染，那么触发离屏渲染的位置会被标记为黄色。

### 如何实现以下图层并不触发离屏渲染

![imageBorder](/Users/icbc_app_2/Desktop/技术分享-offScreenRendering/imageBorder.jpg)

![shadow](/Users/icbc_app_2/Desktop/技术分享-offScreenRendering/shadow.jpeg)

### **AsyncDisplayKit**

AsyncDisplayKit 是 Facebook 开源的一个用于保持 iOS 界面流畅的库，ASDK 的作者是 Scott Goodson，他曾经在苹果工作，负责 iOS 的一些内置应用的开发，比如股票、计算器、地图、钟表、设置、Safari 等，当然他也参与了 UIKit framework 的开发。后来他加入 Facebook 后，负责 Paper 的开发，创建并开源了 AsyncDisplayKit。目前他在 Pinterest 和 Instagram 负责 iOS 开发和用户体验的提升等工作。

